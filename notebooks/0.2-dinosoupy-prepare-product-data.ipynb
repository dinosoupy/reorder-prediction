{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a794587-10e8-4f5f-981c-a501cae9df43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dea45bd-facf-40df-92fd-018251576341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_1d(array, max_len):\n",
    "    array = array[:max_len]\n",
    "    length = len(array)\n",
    "    padded = array + [0]*(max_len - len(array))\n",
    "    return padded, length\n",
    "\n",
    "\n",
    "def make_word_idx(product_names):\n",
    "    words = [word for name in product_names for word in name.split()]\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    max_id = 1\n",
    "    word_idx = {}\n",
    "    for word, count in word_counts.items():\n",
    "        if count < 10:\n",
    "            word_idx[word] = 0\n",
    "        else:\n",
    "            word_idx[word] = max_id\n",
    "            max_id += 1\n",
    "\n",
    "    return word_idx\n",
    "\n",
    "\n",
    "def encode_text(text, word_idx):\n",
    "    return ' '.join([str(word_idx[i]) for i in text.split()]) if text else '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabee70c-668d-4578-bb9a-8fc0f4d30fe2",
   "metadata": {},
   "source": [
    "First we process user data into user_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe05b14b-e403-4541-b995-04dba97ddd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_order(x):\n",
    "    series = pd.Series(dtype='float64')\n",
    "\n",
    "    series['products'] = '_'.join(x['product_id'].values.astype(str).tolist())\n",
    "    series['reorders'] = '_'.join(x['reordered'].values.astype(str).tolist())\n",
    "    series['aisles'] = '_'.join(x['aisle_id'].values.astype(str).tolist())\n",
    "    series['departments'] = '_'.join(x['department_id'].values.astype(str).tolist())\n",
    "\n",
    "    series['order_number'] = x['order_number'].iloc[0]\n",
    "    series['order_dow'] = x['order_dow'].iloc[0]\n",
    "    series['order_hour'] = x['order_hour_of_day'].iloc[0]\n",
    "    series['days_since_prior_order'] = x['days_since_prior_order'].iloc[0]\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def parse_user(x):\n",
    "    parsed_orders = x.groupby('order_id', sort=False).apply(parse_order)\n",
    "\n",
    "    series = pd.Series(dtype='float64')\n",
    "\n",
    "    series['order_ids'] = ' '.join(parsed_orders.index.map(str).tolist())\n",
    "    series['order_numbers'] = ' '.join(parsed_orders['order_number'].map(str).tolist())\n",
    "    series['order_dows'] = ' '.join(parsed_orders['order_dow'].map(str).tolist())\n",
    "    series['order_hours'] = ' '.join(parsed_orders['order_hour'].map(str).tolist())\n",
    "    series['days_since_prior_orders'] = ' '.join(parsed_orders['days_since_prior_order'].map(str).tolist())\n",
    "\n",
    "    series['product_ids'] = ' '.join(parsed_orders['products'].values.astype(str).tolist())\n",
    "    series['aisle_ids'] = ' '.join(parsed_orders['aisles'].values.astype(str).tolist())\n",
    "    series['department_ids'] = ' '.join(parsed_orders['departments'].values.astype(str).tolist())\n",
    "    series['reorders'] = ' '.join(parsed_orders['reorders'].values.astype(str).tolist())\n",
    "\n",
    "    series['eval_set'] = x['eval_set'].values[-1]\n",
    "\n",
    "    return series\n",
    "\n",
    "orders = pd.read_csv('../data/raw/orders.csv')\n",
    "prior_products = pd.read_csv('../data/raw/order_products__prior.csv')\n",
    "train_products = pd.read_csv('../data/raw/order_products__train.csv')\n",
    "order_products = pd.concat([prior_products, train_products], axis=0)\n",
    "products = pd.read_csv('../data/raw/products.csv')\n",
    "\n",
    "df = orders.merge(order_products, how='left', on='order_id')\n",
    "df = df.merge(products, how='left', on='product_id')\n",
    "df['days_since_prior_order'] = df['days_since_prior_order'].fillna(0).astype(int)\n",
    "null_cols = ['product_id', 'aisle_id', 'department_id', 'add_to_cart_order', 'reordered']\n",
    "df[null_cols] = df[null_cols].fillna(0).astype(int)\n",
    "\n",
    "if not os.path.isdir('../data/processed'):\n",
    "    os.makedirs('../data/processed')\n",
    "\n",
    "user_data = df.groupby('user_id', sort=False).apply(parse_user).reset_index()\n",
    "user_data.to_csv('../data/processed/user_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f48d76-7e23-4105-9a7c-0a2af7b6d70c",
   "metadata": {},
   "source": [
    "Then we process product.csv to create product_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88609754-684c-42d4-b135-fb7475da3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    df = pd.read_csv('../data/processed/user_data.csv')\n",
    "\n",
    "    products = pd.read_csv('../data/raw/products.csv')\n",
    "    product_to_aisle = dict(zip(products['product_id'], products['aisle_id']))\n",
    "    product_to_department = dict(zip(products['product_id'], products['department_id']))\n",
    "    product_to_name = dict(zip(products['product_id'], products['product_name']))\n",
    "\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    aisle_ids = []\n",
    "    department_ids = []\n",
    "    product_names = []\n",
    "    eval_sets = []\n",
    "\n",
    "    is_ordered_histories = []\n",
    "    index_in_order_histories = []\n",
    "    order_size_histories = []\n",
    "    reorder_size_histories = []\n",
    "    order_dow_histories = []\n",
    "    order_hour_histories = []\n",
    "    days_since_prior_order_histories = []\n",
    "    order_number_histories = []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    longest = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if _ % 10000 == 0:\n",
    "            print _\n",
    "\n",
    "        user_id = row['user_id']\n",
    "        eval_set = row['eval_set']\n",
    "        products = row['product_ids']\n",
    "\n",
    "        products, next_products = ' '.join(products.split()[:-1]), products.split()[-1]\n",
    "\n",
    "        reorders = row['reorders']\n",
    "        reorders, next_reorders = ' '.join(reorders.split()[:-1]), reorders.split()[-1]\n",
    "\n",
    "        product_set = set([int(j) for i in products.split() for j in i.split('_')])\n",
    "        next_product_set = set([int(i) for i in next_products.split('_')])\n",
    "\n",
    "        orders = [map(int, i.split('_')) for i in products.split()]\n",
    "        reorders = [map(int, i.split('_')) for i in reorders.split()]\n",
    "        next_reorders = map(int, next_reorders.split('_'))\n",
    "\n",
    "        for product_id in product_set:\n",
    "\n",
    "            user_ids.append(user_id)\n",
    "            product_ids.append(product_id)\n",
    "            labels.append(int(product_id in next_product_set) if eval_set == 'train' else -1)\n",
    "\n",
    "            aisle_ids.append(product_to_aisle[product_id])\n",
    "            department_ids.append(product_to_department[product_id])\n",
    "            product_names.append(product_to_name[product_id])\n",
    "            eval_sets.append(eval_set)\n",
    "\n",
    "            is_ordered = []\n",
    "            index_in_order = []\n",
    "            order_size = []\n",
    "            reorder_size = []\n",
    "\n",
    "            prior_products = set()\n",
    "            for order in orders:\n",
    "                is_ordered.append(str(int(product_id in order)))\n",
    "                index_in_order.append(str(order.index(product_id) + 1) if product_id in order else '0')\n",
    "                order_size.append(str(len(order)))\n",
    "                reorder_size.append(str(len(prior_products & set(order))))\n",
    "                prior_products |= set(order)\n",
    "\n",
    "            is_ordered = ' '.join(is_ordered)\n",
    "            index_in_order = ' '.join(index_in_order)\n",
    "            order_size = ' '.join(order_size)\n",
    "            reorder_size = ' '.join(reorder_size)\n",
    "\n",
    "            is_ordered_histories.append(is_ordered)\n",
    "            index_in_order_histories.append(index_in_order)\n",
    "            order_size_histories.append(order_size)\n",
    "            reorder_size_histories.append(reorder_size)\n",
    "            order_dow_histories.append(row['order_dows'])\n",
    "            order_hour_histories.append(row['order_hours'])\n",
    "            days_since_prior_order_histories.append(row['days_since_prior_orders'])\n",
    "            order_number_histories.append(row['order_numbers'])\n",
    "\n",
    "        user_ids.append(user_id)\n",
    "        product_ids.append(0)\n",
    "        labels.append(int(max(next_reorders) == 0) if eval_set == 'train' else -1)\n",
    "\n",
    "        aisle_ids.append(0)\n",
    "        department_ids.append(0)\n",
    "        product_names.append(0)\n",
    "        eval_sets.append(eval_set)\n",
    "\n",
    "        is_ordered = []\n",
    "        index_in_order = []\n",
    "        order_size = []\n",
    "        reorder_size = []\n",
    "\n",
    "        for reorder in reorders:\n",
    "            is_ordered.append(str(int(max(reorder) == 0)))\n",
    "            index_in_order.append(str(0))\n",
    "            order_size.append(str(len(reorder)))\n",
    "            reorder_size.append(str(sum(reorder)))\n",
    "\n",
    "        is_ordered = ' '.join(is_ordered)\n",
    "        index_in_order = ' '.join(index_in_order)\n",
    "        order_size = ' '.join(order_size)\n",
    "        reorder_size = ' '.join(reorder_size)\n",
    "\n",
    "        is_ordered_histories.append(is_ordered)\n",
    "        index_in_order_histories.append(index_in_order)\n",
    "        order_size_histories.append(order_size)\n",
    "        reorder_size_histories.append(reorder_size)\n",
    "        order_dow_histories.append(row['order_dows'])\n",
    "        order_hour_histories.append(row['order_hours'])\n",
    "        days_since_prior_order_histories.append(row['days_since_prior_orders'])\n",
    "        order_number_histories.append(row['order_numbers'])\n",
    "\n",
    "    data = [\n",
    "        user_ids,\n",
    "        product_ids,\n",
    "        aisle_ids,\n",
    "        department_ids,\n",
    "        product_names,\n",
    "        is_ordered_histories,\n",
    "        index_in_order_histories,\n",
    "        order_size_histories,\n",
    "        reorder_size_histories,\n",
    "        order_dow_histories,\n",
    "        order_hour_histories,\n",
    "        days_since_prior_order_histories,\n",
    "        order_number_histories,\n",
    "        labels,\n",
    "        eval_sets\n",
    "    ]\n",
    "    columns = [\n",
    "        'user_id',\n",
    "        'product_id',\n",
    "        'aisle_id',\n",
    "        'department_id',\n",
    "        'product_name',\n",
    "        'is_ordered_history',\n",
    "        'index_in_order_history',\n",
    "        'order_size_history',\n",
    "        'reorder_size_history',\n",
    "        'order_dow_history',\n",
    "        'order_hour_history',\n",
    "        'days_since_prior_order_history',\n",
    "        'order_number_history',\n",
    "        'label',\n",
    "        'eval_set'\n",
    "    ]\n",
    "    if not os.path.isdir('../data/processed'):\n",
    "        os.makedirs('../data/processed')\n",
    "\n",
    "    df = pd.DataFrame(dict(zip(columns, data)))\n",
    "    df.to_csv('../data/processed/product_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c182b-45f6-4e61-a87f-2a648a49725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = pd.read_csv('../data/raw/product_data.csv')\n",
    "product_data['product_name'] = product_data['product_name'].map(lambda x: x.lower())\n",
    "\n",
    "product_df = pd.read_csv('../data/raw/products.csv')\n",
    "product_df['product_name'] = product_df['product_name'].map(lambda x: x.lower())\n",
    "\n",
    "word_idx = make_word_idx(product_df['product_name'].tolist())\n",
    "product_data['product_name_encoded'] = product_data['product_name'].map(lambda x: encode_text(x, word_idx))\n",
    "\n",
    "num_rows = len(product_data)\n",
    "\n",
    "user_id = np.zeros(shape=[num_rows], dtype=np.int32)\n",
    "product_id = np.zeros(shape=[num_rows], dtype=np.int32)\n",
    "aisle_id = np.zeros(shape=[num_rows], dtype=np.int16)\n",
    "department_id = np.zeros(shape=[num_rows], dtype=np.int8)\n",
    "eval_set = np.zeros(shape=[num_rows], dtype='S5')\n",
    "label = np.zeros(shape=[num_rows], dtype=np.int8)\n",
    "\n",
    "is_ordered_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "index_in_order_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "order_dow_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "order_hour_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "days_since_prior_order_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "order_size_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "reorder_size_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "order_number_history = np.zeros(shape=[num_rows, 100], dtype=np.int8)\n",
    "product_name = np.zeros(shape=[num_rows, 30], dtype=np.int32)\n",
    "product_name_length = np.zeros(shape=[num_rows], dtype=np.int8)\n",
    "history_length = np.zeros(shape=[num_rows], dtype=np.int8)\n",
    "\n",
    "for i, row in product_data.iterrows():\n",
    "    if i % 10000 == 0:\n",
    "        print i, num_rows\n",
    "\n",
    "    user_id[i] = row['user_id']\n",
    "    product_id[i] = row['product_id']\n",
    "    aisle_id[i] = row['aisle_id']\n",
    "    department_id[i] = row['department_id']\n",
    "    eval_set[i] = row['eval_set']\n",
    "    label[i] = row['label']\n",
    "\n",
    "    is_ordered_history[i, :], history_length[i] = pad_1d(map(int, row['is_ordered_history'].split()), 100)\n",
    "    index_in_order_history[i, :], _ = pad_1d(map(int, row['index_in_order_history'].split()), 100)\n",
    "    order_dow_history[i, :], _ = pad_1d(map(int, row['order_dow_history'].split()), 100)\n",
    "    order_hour_history[i, :], _ = pad_1d(map(int, row['order_hour_history'].split()), 100)\n",
    "    days_since_prior_order_history[i, :], _ = pad_1d(map(int, row['days_since_prior_order_history'].split()), 100)\n",
    "    order_size_history[i, :], _ = pad_1d(map(int, row['order_size_history'].split()), 100)\n",
    "    reorder_size_history[i, :], _ = pad_1d(map(int, row['reorder_size_history'].split()), 100)\n",
    "    order_number_history[i, :], _ = pad_1d(map(int, row['order_number_history'].split()), 100)\n",
    "    product_name[i, :], product_name_length[i] = pad_1d(map(int, row['product_name_encoded'].split()), 30)\n",
    "\n",
    "if not os.path.isdir('data/interim'):\n",
    "    os.makedirs('data/interim')\n",
    "\n",
    "np.save('data/interim/user_id.npy', user_id)\n",
    "np.save('data/interim/product_id.npy', product_id)\n",
    "np.save('data/interim/aisle_id.npy', aisle_id)\n",
    "np.save('data/interim/department_id.npy', department_id)\n",
    "np.save('data/interim/eval_set.npy', eval_set)\n",
    "np.save('data/interim/label.npy', label)\n",
    "\n",
    "np.save('data/interim/is_ordered_history.npy', is_ordered_history)\n",
    "np.save('data/interim/index_in_order_history.npy', index_in_order_history)\n",
    "np.save('data/interim/order_dow_history.npy', order_dow_history)\n",
    "np.save('data/interim/order_hour_history.npy', order_hour_history)\n",
    "np.save('data/interim/days_since_prior_order_history.npy', days_since_prior_order_history)\n",
    "np.save('data/interim/order_size_history.npy', order_size_history)\n",
    "np.save('data/interim/reorder_size_history.npy', reorder_size_history)\n",
    "np.save('data/interim/order_number_history.npy', order_number_history)\n",
    "np.save('data/interim/product_name.npy', product_name)\n",
    "np.save('data/interim/product_name_length.npy', product_name_length)\n",
    "np.save('data/interim/history_length.npy', history_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
