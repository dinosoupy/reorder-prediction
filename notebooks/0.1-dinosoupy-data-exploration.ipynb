{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3e4c0b-cdd9-4ad7-aa3d-2f1e1d2f02e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39186d23-3eed-4a56-9692-cdd754b391f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66658fe-18ff-4655-add6-6cdf725c065f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products.csv\n",
      "orders.csv\n",
      "order_products__train.csv\n",
      "departments.csv\n",
      "aisles.csv\n",
      "order_products__prior.csv\n",
      "sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(RAW_DATA_PATH)\n",
    "\n",
    "\n",
    "# Filter and print only the files with .csv extension\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ab46b1e-de50-400b-904e-5ff5fc00a45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_orders():\n",
    "    '''\n",
    "        get order context information\n",
    "    '''\n",
    "    \n",
    "    # \n",
    "\n",
    "    # return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0da89a83-3519-4d02-8bb2-6927036ea52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2398795        1    prior             2          3                  7   \n",
      "2    473747        1    prior             3          3                 12   \n",
      "3   2254736        1    prior             4          4                  7   \n",
      "4    431534        1    prior             5          4                 15   \n",
      "\n",
      "   days_since_prior_order  days_up_to_last  \n",
      "0                     0.0            190.0  \n",
      "1                    15.0            175.0  \n",
      "2                    21.0            154.0  \n",
      "3                    29.0            125.0  \n",
      "4                    28.0             97.0  \n"
     ]
    }
   ],
   "source": [
    "orders = pd.read_csv(RAW_DATA_PATH + 'orders.csv')\n",
    "orders = orders.fillna(0.0)\n",
    "orders['days'] = orders.groupby(['user_id'])['days_since_prior_order'].cumsum()\n",
    "orders['days_last'] = orders.groupby(['user_id'])['days'].transform(max)\n",
    "orders['days_up_to_last'] = orders['days_last'] - orders['days']\n",
    "del orders['days_last']\n",
    "del orders['days']\n",
    "print(orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702541f-a14e-45cb-b06f-4cb2ed09f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "    Prepare Input for DREAM \n",
    "    Based on the Instartcart Dataset\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pdb\n",
    "\n",
    "class BasketConstructor(object):\n",
    "    '''\n",
    "        Group products into baskets(type: list)\n",
    "    '''\n",
    "    def __init__(self, raw_data_dir, cache_dir):\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self.cache_dir = cache_dir\n",
    "    \n",
    "    def get_orders(self):\n",
    "        '''\n",
    "            get order context information\n",
    "        '''\n",
    "        orders = pd.read_csv(self.raw_data_dir + 'orders.csv')\n",
    "        orders = orders.fillna(0.0)\n",
    "        orders['days'] = orders.groupby(['user_id'])['days_since_prior_order'].cumsum()\n",
    "        orders['days_last'] = orders.groupby(['user_id'])['days'].transform(max)\n",
    "        orders['days_up_to_last'] = orders['days_last'] - orders['days']\n",
    "        del orders['days_last']\n",
    "        del orders['days']\n",
    "        return orders\n",
    "    \n",
    "    def get_orders_items(self, prior_or_train):\n",
    "        '''\n",
    "            get detailed information of prior or train orders \n",
    "        '''\n",
    "        orders_products = pd.read_csv(self.raw_data_dir + 'order_products__%s.csv'%prior_or_train)\n",
    "        return orders_products\n",
    "    \n",
    "\n",
    "    def get_users_orders(self, prior_or_train):\n",
    "        '''\n",
    "            get users' prior detailed orders\n",
    "        '''\n",
    "        if os.path.exists(self.cache_dir + 'users_orders.pkl'):\n",
    "            with open(self.cache_dir + 'users_orders.pkl', 'rb') as f:\n",
    "                users_orders = pickle.load(f)\n",
    "        else:\n",
    "            orders = self.get_orders()\n",
    "            order_products_prior = self.get_orders_items(prior_or_train)\n",
    "            users_orders = pd.merge(order_products_prior, orders[['user_id', 'order_id', 'order_number', 'days_up_to_last']], \n",
    "                        on = ['order_id'], how = 'left')\n",
    "            with open(self.cache_dir + 'users_orders.pkl', 'wb') as f:\n",
    "                pickle.dump(users_orders, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return users_orders\n",
    "    \n",
    "    def get_users_products(self, prior_or_train):\n",
    "        '''\n",
    "            get users' all purchased products\n",
    "        '''\n",
    "        if os.path.exists(self.cache_dir + 'users_products.pkl'):\n",
    "            with open(self.cache_dir + 'users_products.pkl', 'rb') as f:\n",
    "                users_products = pickle.load(f)\n",
    "        else:\n",
    "            users_products = self.get_users_orders(prior_or_train)[['user_id', 'product_id']].drop_duplicates()\n",
    "            users_products['product_id'] = users_products.product_id.astype(int)\n",
    "            users_products['user_id'] = users_products.user_id.astype(int)\n",
    "            users_products = users_products.groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            with open(self.cache_dir + 'users_products.pkl', 'wb') as f:\n",
    "                pickle.dump(users_products, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return users_products\n",
    "\n",
    "    def get_items(self, gran):\n",
    "        '''\n",
    "            get items' information\n",
    "            gran = [departments, aisles, products]\n",
    "        '''\n",
    "        items = pd.read_csv(self.raw_data_dir + '%s.csv'%gran)\n",
    "        return items\n",
    "    \n",
    "    def get_baskets(self, prior_or_train, reconstruct = False, reordered = False, none_idx = 49689):\n",
    "        '''\n",
    "            get users' baskets\n",
    "        '''\n",
    "        if reordered:\n",
    "            filepath = self.cache_dir + './reorder_basket_' + prior_or_train + '.pkl'\n",
    "        else:\n",
    "            filepath = self.cache_dir + './basket_' + prior_or_train + '.pkl'\n",
    "       \n",
    "        if (not reconstruct) and os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                up_basket = pickle.load(f)\n",
    "        else:          \n",
    "            up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "            uid_oid = up[['user_id', 'order_number']].drop_duplicates()\n",
    "            up = up[up.reordered == 1][['user_id', 'order_number', 'product_id']] if reordered else up[['user_id', 'order_number', 'product_id']]\n",
    "            up_basket = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "            up_basket = pd.merge(uid_oid, up_basket, on = ['user_id', 'order_number'], how = 'left')\n",
    "            for row in up_basket.loc[up_basket.product_id.isnull(), 'product_id'].index:\n",
    "                up_basket.at[row, 'product_id'] = [none_idx]\n",
    "            up_basket = up_basket.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            up_basket.columns = ['user_id', 'reorder_basket'] if reordered else ['user_id', 'basket']\n",
    "            #pdb.set_trace()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(up_basket, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return up_basket\n",
    "        \n",
    "    def get_item_history(self, prior_or_train, reconstruct = False, none_idx = 49689):\n",
    "        filepath = self.cache_dir + './item_history_' + prior_or_train + '.pkl'\n",
    "        if (not reconstruct) and os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                item_history = pickle.load(f)\n",
    "        else:\n",
    "            up = self.get_users_orders(prior_or_train).sort_values(['user_id', 'order_number', 'product_id'], ascending = True)\n",
    "            item_history = up.groupby(['user_id', 'order_number'])['product_id'].apply(list).reset_index()\n",
    "            item_history.loc[item_history.order_number == 1, 'product_id'] = item_history.loc[item_history.order_number == 1, 'product_id'] + [none_idx]\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "            # accumulate \n",
    "            item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].transform(pd.Series.cumsum)\n",
    "            # get unique item list\n",
    "            item_history['product_id'] = item_history['product_id'].apply(set).apply(list)\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True)\n",
    "            # shift each group to make it history\n",
    "            item_history['product_id'] = item_history.groupby(['user_id'])['product_id'].shift(1)\n",
    "            for row in item_history.loc[item_history.product_id.isnull(), 'product_id'].index:\n",
    "                item_history.at[row, 'product_id'] = [none_idx]\n",
    "            item_history = item_history.sort_values(['user_id', 'order_number'], ascending = True).groupby(['user_id'])['product_id'].apply(list).reset_index()\n",
    "            item_history.columns = ['user_id', 'history_items']\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(item_history, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return item_history \n",
    "\n",
    "class Dataset(object):\n",
    "    '''\n",
    "        Dataset prepare from user-basket\n",
    "    '''\n",
    "    def __init__(self, up_basket, up_r_basket = None, up_his = None):\n",
    "        if (up_r_basket is not None) and (up_his is not None):\n",
    "            self.is_reordered_included = True\n",
    "        else:\n",
    "            self.is_reordered_included = False\n",
    "\n",
    "        up_basket['num_baskets'] = up_basket.basket.apply(len)\n",
    "        self.user_id = list(up_basket.user_id)\n",
    "        self.num_baskets = [int(n) for n in list(up_basket.num_baskets)]    \n",
    "        self.basket = [[[int(p) for p in b]for b in u] for u in list(up_basket.basket)]\n",
    "\n",
    "        if self.is_reordered_included is True:\n",
    "            up_basket = pd.merge(up_basket, up_r_basket, on = ['user_id'], how = 'left')\n",
    "            up_basket = pd.merge(up_basket, up_his, on = ['user_id'], how = 'left')\n",
    "            self.reorder_basket = [[[int(p) for p in b]for b in u] for u in list(up_basket.reorder_basket)]\n",
    "            self.history_item = [[[int(p) for p in b]for b in u] for u in list(up_basket.history_items)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "            return baskets & num_baskets\n",
    "        '''\n",
    "        if self.is_reordered_included is True:\n",
    "            return self.basket[index], self.num_baskets[index], self.user_id[index], self.reorder_basket[index], self.history_item[index]\n",
    "        else:\n",
    "            return self.basket[index], self.num_baskets[index], self.user_id[index]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.user_id)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
