{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210cd95-37a5-49fe-8ece-9bf8868e5373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from data_frame import DataFrame\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Conv1D, Activation, Add, Multiply, Lambda, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from utils import lstm_layer, time_distributed_dense_layer, dense_layer, wavenet\n",
    "import tabnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d46a040d-73dc-4a63-994e-2adc4e138620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/interim'\n",
    "data_cols = [\n",
    "            'user_id',\n",
    "            'product_id',\n",
    "            'aisle_id',\n",
    "            'department_id',\n",
    "            # 'is_ordered_history',\n",
    "            # 'index_in_order_history',\n",
    "            # 'order_dow_history',\n",
    "            # 'order_hour_history',\n",
    "            # 'days_since_prior_order_history',\n",
    "            # 'order_size_history',\n",
    "            # 'reorder_size_history',\n",
    "            # 'order_number_history',\n",
    "            # 'history_length',\n",
    "            # 'product_name',\n",
    "            # 'product_name_length',\n",
    "            # 'eval_set',\n",
    "            'label'\n",
    "        ]\n",
    "\n",
    "data = { i : np.load(os.path.join(data_dir, '{}.npy'.format(i)), mmap_mode='r') for i in data_cols }\n",
    "# test_df = DataFrame(columns=data_cols, data=data)\n",
    "                        \n",
    "# print(test_df.shapes())\n",
    "# print('loaded data')\n",
    "\n",
    "# train_df, val_df = test_df.train_test_split(train_size=0.8)\n",
    "\n",
    "# print('train size', len(train_df))\n",
    "# print('val size', len(val_df))\n",
    "# print('test size', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbab399b-4b13-4300-8f05-6b55459f3efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user_id\n",
      "Shape:  user_id\n",
      "Dtype:  0    int32\n",
      "dtype: object\n",
      "Row:     0\n",
      "0  1\n",
      "\n",
      "product_id\n",
      "Shape:  product_id\n",
      "Dtype:  0    int32\n",
      "dtype: object\n",
      "Row:         0\n",
      "0  17122\n",
      "\n",
      "aisle_id\n",
      "Shape:  aisle_id\n",
      "Dtype:  0    int16\n",
      "dtype: object\n",
      "Row:      0\n",
      "0  24\n",
      "\n",
      "department_id\n",
      "Shape:  department_id\n",
      "Dtype:  0    int8\n",
      "dtype: object\n",
      "Row:     0\n",
      "0  4\n",
      "\n",
      "label\n",
      "Shape:  label\n",
      "Dtype:  0    int8\n",
      "dtype: object\n",
      "Row:     0\n",
      "0  0\n"
     ]
    }
   ],
   "source": [
    "for k in data:\n",
    "    df = pd.DataFrame(data[k])\n",
    "    print()\n",
    "    print(k)\n",
    "    print(\"Shape: \", k)\n",
    "    print(\"Dtype: \", df.dtypes)\n",
    "    print(\"Row: \", df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36480c5b-3f0f-43a8-adcb-12c85640cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d34897d5-a69e-471d-9b46-d6de0b6925dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input layers\n",
    "user_id = Input(shape=(), dtype=tf.int32, name='user_id')\n",
    "product_id = Input(shape=(), dtype=tf.int32, name='product_id')\n",
    "aisle_id = Input(shape=(), dtype=tf.int32, name='aisle_id')\n",
    "department_id = Input(shape=(), dtype=tf.int32, name='department_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd29def7-792f-41ee-9efd-fd80b3b3f818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'TensorShape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [user_id, product_id, aisle_id, department_id]\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m tabnet_model\u001b[38;5;241m.\u001b[39mTabNetEncoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtabnet_params)(inputs)\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m)(x)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs, output)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/repos/reorder-prediction/notebooks/tabnet_model.py:359\u001b[0m, in \u001b[0;36mTabNetEncoder.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n\u001b[1;32m    351\u001b[0m     feature_transformer \u001b[38;5;241m=\u001b[39m FeatureTransformer(\n\u001b[1;32m    352\u001b[0m         n_dependent_glus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dependent_glus, \n\u001b[1;32m    353\u001b[0m         shared_glu_fc_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_glu_fc_layers, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatureTransformer_Step_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    358\u001b[0m     )\n\u001b[0;32m--> 359\u001b[0m     attentive_transformer \u001b[38;5;241m=\u001b[39m AttentiveTransformer(\n\u001b[1;32m    360\u001b[0m         units\u001b[38;5;241m=\u001b[39mfeature_dim, \n\u001b[1;32m    361\u001b[0m         n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps, \n\u001b[1;32m    362\u001b[0m         epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon, \n\u001b[1;32m    363\u001b[0m         lambda_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_sparse, \n\u001b[1;32m    364\u001b[0m         virtual_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size, \n\u001b[1;32m    365\u001b[0m         momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum, \n\u001b[1;32m    366\u001b[0m         mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_type, \n\u001b[1;32m    367\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttentiveTransformer_Step_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_feature_transformers\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    370\u001b[0m         feature_transformer\n\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_attentive_transformers\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    373\u001b[0m         attentive_transformer\n\u001b[1;32m    374\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/reorder-prediction/notebooks/tabnet_model.py:211\u001b[0m, in \u001b[0;36mAttentiveTransformer.__init__\u001b[0;34m(self, units, n_steps, epsilon, lambda_sparse, virtual_batch_size, momentum, mask_type, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_sparse \u001b[38;5;241m=\u001b[39m lambda_sparse\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# attentive transformer layers\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(units, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization(virtual_batch_size\u001b[38;5;241m=\u001b[39mvirtual_batch_size, \n\u001b[1;32m    214\u001b[0m                                              momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparsemax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'TensorShape'"
     ]
    }
   ],
   "source": [
    "inputs = [user_id, product_id, aisle_id, department_id]\n",
    "x = tabnet_model.TabNetEncoder(**tabnet_params)(inputs)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2dabcdb-69d0-48a0-a1ae-47b5da76b0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabnet_params = {\n",
    "        \"decision_dim\": 16, \n",
    "        \"attention_dim\": 16, \n",
    "        \"n_steps\": 5, \n",
    "        \"n_shared_glus\": 2, \n",
    "        \"n_dependent_glus\": 2, \n",
    "        \"relaxation_factor\": 1.5, \n",
    "        \"epsilon\": 1e-15, \n",
    "        \"virtual_batch_size\": None, \n",
    "        \"momentum\": 0.98, \n",
    "        \"mask_type\": \"entmax\", \n",
    "        \"lambda_sparse\": 1e-4, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b44e0-4f02-4229-a5d7-56b86a22a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model using Functional API\n",
    "inputs = create_keras_input_layer(data_cols)\n",
    "x = encode_features(inputs, feature_names, \n",
    "                    cat_str_feature_names, cat_int_feature_names, cat_embed_dims, \n",
    "                    train_ds)\n",
    "x = tf.keras.layers.Concatenate()(x)\n",
    "x = tabnet_model.TabNetEncoder(**tabnet_params)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
